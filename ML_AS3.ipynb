{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf377c2a-0cd6-4718-bf7e-1e2ae8294937",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6659136b-7998-415f-ac49-ecd3b4f5c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of scaled features:\n",
      " [[ 2.34476576  0.98214266  0.62855945 -0.15375759 -0.9744286  -0.04959654\n",
      "   1.05254828 -1.32783522]\n",
      " [ 2.33223796 -0.60701891  0.32704136 -0.26333577  0.86143887 -0.09251223\n",
      "   1.04318455 -1.32284391]\n",
      " [ 1.7826994   1.85618152  1.15562047 -0.04901636 -0.82077735 -0.02584253\n",
      "   1.03850269 -1.33282653]\n",
      " [ 0.93296751  1.85618152  0.15696608 -0.04983292 -0.76602806 -0.0503293\n",
      "   1.03850269 -1.33781784]\n",
      " [-0.012881    1.85618152  0.3447108  -0.03290586 -0.75984669 -0.08561576\n",
      "   1.03850269 -1.33781784]]\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Import libraries\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ðŸ“¥ Load the California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "\n",
    "# Add target variable (Median House Value)\n",
    "df['median_house_value'] = housing.target\n",
    "\n",
    "# Handle missing values (None in this dataset)\n",
    "# The dataset doesn't have missing values, but you can fill or drop if required\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Standardizing features (feature scaling)\n",
    "scaler = StandardScaler()\n",
    "X = df.drop('median_house_value', axis=1)\n",
    "y = df['median_house_value']\n",
    "\n",
    "# Scaling the features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"First 5 rows of scaled features:\\n\", X_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948790e8-c852-4e6c-8587-af084d13aa32",
   "metadata": {},
   "source": [
    "### Loading Dataset: We use fetch_california_housing to load the data.\n",
    "\n",
    "Convert to DataFrame: This makes it easier to manipulate and explore.\n",
    "\n",
    "Missing Values: There are no missing values in this dataset, but I included a step for handling them (e.g., filling with the mean).\n",
    "\n",
    "Feature Scaling: We use StandardScaler to standardize the features to ensure all variables have equal importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34075409-98f2-4342-a615-4e6138a4beaf",
   "metadata": {},
   "source": [
    "## Regression Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea06d43-86f5-413d-8ac6-b51386729b76",
   "metadata": {},
   "source": [
    "## Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a531a7f-897a-4167-81f0-5d5b92ee157f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.5558915986952441\n",
      "Linear Regression MAE: 0.5332001304956565\n",
      "Linear Regression R2: 0.575787706032451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Linear Regression Model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Linear Regression MSE:\", mse_lr)\n",
    "print(\"Linear Regression MAE:\", mae_lr)\n",
    "print(\"Linear Regression R2:\", r2_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4323fd85-c561-46cd-af09-7fec180efe0b",
   "metadata": {},
   "source": [
    "### Linear Regression fits a linear equation to model the relationship between features and the target.\n",
    "\n",
    "It's simple and suitable if the data has a linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0e56b-ba7e-49d3-985a-8c8e2288debe",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95a77787-76e8-4b76-ac0c-755d26d3834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 0.4942716777366763\n",
      "Decision Tree MAE: 0.4537843265503876\n",
      "Decision Tree R2: 0.6228111330554302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Decision Tree Regressor Model\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree MSE:\", mse_dt)\n",
    "print(\"Decision Tree MAE:\", mae_dt)\n",
    "print(\"Decision Tree R2:\", r2_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74934901-e6b5-4ff1-98b5-2deaa8cae8d0",
   "metadata": {},
   "source": [
    "### Decision Trees split the data into segments based on feature values.\n",
    "\n",
    "Itâ€™s suitable for capturing non-linear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327d92c-64ee-4491-ad8b-1d925cd586c7",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1ecfb44-5821-4ef3-a985-9899d408af73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 0.25549776668540763\n",
      "Random Forest MAE: 0.32761306601259704\n",
      "Random Forest R2: 0.805024407701793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest Regressor Model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest MSE:\", mse_rf)\n",
    "print(\"Random Forest MAE:\", mae_rf)\n",
    "print(\"Random Forest R2:\", r2_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609cb3ab-fa8d-419b-91a6-4fa3dac94134",
   "metadata": {},
   "source": [
    "### Random Forest is an ensemble of decision trees, making it more robust and less prone to overfitting.\n",
    "\n",
    "It handles complex datasets well and works for non-linear data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560eedb-92d8-4154-ad39-ca6a86880699",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "463e7855-2d50-498b-bbb3-27840dc573df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting MSE: 0.29399901242474274\n",
      "Gradient Boosting MAE: 0.37165044848436773\n",
      "Gradient Boosting R2: 0.7756433164710084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Gradient Boosting Regressor Model\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "print(\"Gradient Boosting MSE:\", mse_gb)\n",
    "print(\"Gradient Boosting MAE:\", mae_gb)\n",
    "print(\"Gradient Boosting R2:\", r2_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fc59ef-6777-4abb-94ac-7b18988586bb",
   "metadata": {},
   "source": [
    "### Gradient Boosting iteratively corrects errors made by previous models, which improves its predictive power.\n",
    "\n",
    "Suitable for complex data and tends to perform well for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb1699-8678-4385-9080-5ab97cc16d75",
   "metadata": {},
   "source": [
    "## Support Vector Regressor (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19ff3495-a80f-45f2-8c69-0489defcd469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR MSE: 0.3551984619989429\n",
      "SVR MAE: 0.397763096343787\n",
      "SVR R2: 0.7289407597956454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Support Vector Regressor Model\n",
    "svr = SVR(kernel='rbf')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svr = svr.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "print(\"SVR MSE:\", mse_svr)\n",
    "print(\"SVR MAE:\", mae_svr)\n",
    "print(\"SVR R2:\", r2_svr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c3693-cf75-4b5d-8abc-1e11c7534cae",
   "metadata": {},
   "source": [
    "### SVR creates a boundary (hyperplane) that fits the data with minimal error.\n",
    "\n",
    "It's good for capturing non-linear relationships but may be slow for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c30ab-9096-4a62-8f2b-5ee380ae20bf",
   "metadata": {},
   "source": [
    "# Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e594b096-6401-4808-bdd2-828e48c65a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression -> MSE: 0.5558915986952441, MAE: 0.5332001304956565, RÂ²: 0.575787706032451\n",
      "Decision Tree -> MSE: 0.4942716777366763, MAE: 0.4537843265503876, RÂ²: 0.6228111330554302\n",
      "Random Forest -> MSE: 0.25549776668540763, MAE: 0.32761306601259704, RÂ²: 0.805024407701793\n",
      "Gradient Boosting -> MSE: 0.29399901242474274, MAE: 0.37165044848436773, RÂ²: 0.7756433164710084\n",
      "SVR -> MSE: 0.3551984619989429, MAE: 0.397763096343787, RÂ²: 0.7289407597956454\n"
     ]
    }
   ],
   "source": [
    "# Example to compare the models (assuming previous code blocks)\n",
    "models = {\n",
    "    'Linear Regression': (mse_lr, mae_lr, r2_lr),\n",
    "    'Decision Tree': (mse_dt, mae_dt, r2_dt),\n",
    "    'Random Forest': (mse_rf, mae_rf, r2_rf),\n",
    "    'Gradient Boosting': (mse_gb, mae_gb, r2_gb),\n",
    "    'SVR': (mse_svr, mae_svr, r2_svr),\n",
    "}\n",
    "\n",
    "for model_name, (mse, mae, r2) in models.items():\n",
    "    print(f\"{model_name} -> MSE: {mse}, MAE: {mae}, RÂ²: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1cf8d-2ff9-473a-9492-2808515ef104",
   "metadata": {},
   "source": [
    "### Mean Squared Error (MSE): Measures the average squared difference between the predicted and actual values. Lower values indicate better performance.\n",
    "\n",
    "Mean Absolute Error (MAE): Measures the average absolute difference between actual and predicted values. Again, lower values indicate better performance.\n",
    "\n",
    "RÂ² Score: Indicates how well the model explains the variance in the target variable. Higher values are better (closer to 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e65ea-2de8-4900-b201-da30683c0cbb",
   "metadata": {},
   "source": [
    "### Compare Results:\n",
    "The best-performing model would have the lowest MSE, lowest MAE, and the highest RÂ².\n",
    "\n",
    "The worst-performing model will have the highest MSE, highest MAE, and the lowest RÂ²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eebc1a-a597-4148-8f84-c8a723421a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
