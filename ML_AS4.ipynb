{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3343998c-b757-470d-b955-91c87d616336",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e2814c-c87d-4291-88cd-31b502746200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b5fc5b-cbc4-4e02-8b8a-94e51fe7b3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(X.isnull().sum().sum())  # Should be 0 for this dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2641e965-bded-4eaf-9188-df923c60a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f046c5-6236-4f07-a7b1-78ea78e6e480",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "The Breast Cancer dataset from sklearn does not contain missing values, so no imputation is needed.\n",
    "\n",
    "Feature scaling using StandardScaler is essential for models like SVM and k-NN, which are sensitive to the scale of input features. It also helps improve convergence in Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed9bac0-14b4-476e-a121-4103b676e171",
   "metadata": {},
   "source": [
    "# Classification Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523d9df2-5b8b-4589-a634-8e9154ff1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b29238-a993-4e07-8676-9279047cb3cf",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b5eb97-19c3-47bd-b1c8-63b06e75950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920a704-80af-4973-bd88-95ddfa35549d",
   "metadata": {},
   "source": [
    "Description: Logistic Regression models the probability of class membership using the logistic function. It works well for binary classification problems like this one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36fc132-77f7-4a4b-a51e-6bc57979c535",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2538517d-55f2-439d-891a-aed0884695bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, dt_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac84d121-3ead-4811-ad7b-176ad17dfc14",
   "metadata": {},
   "source": [
    "Description: Decision Trees split the data based on feature thresholds. They are interpretable and handle non-linear relationships but can overfit easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0304b9a7-449d-45c6-91ec-b40d2b48455c",
   "metadata": {},
   "source": [
    "##  Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b102380c-7289-4bad-8ee1-b600f4a79028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4148b714-a9af-45fc-9377-aa1f66bb9023",
   "metadata": {},
   "source": [
    "Description: Random Forest is an ensemble method combining many Decision Trees. It improves accuracy and reduces overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3da82-f74a-45dc-a9c4-adba337495bb",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6f2f80-d7e7-4f33-8e35-66a48efa305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55203bf3-a900-4dfd-8114-e9ad76c5a3eb",
   "metadata": {},
   "source": [
    "Description: SVM finds a hyperplane that best separates the classes. It performs well with high-dimensional data and when classes are separable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dec189-5809-4502-bc7f-5059d8383a69",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb2fb415-82b1-4738-946f-024e8a9dc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d33a691-d01c-40b7-b652-1e36b02b6b45",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e35e3d9-1f31-4516-b720-96b48c7d0581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy\n",
      "0  Logistic Regression  0.973684\n",
      "3                  SVM  0.973684\n",
      "2        Random Forest  0.964912\n",
      "1        Decision Tree  0.947368\n",
      "4                 k-NN  0.947368\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"Logistic Regression\": lr_acc,\n",
    "    \"Decision Tree\": dt_acc,\n",
    "    \"Random Forest\": rf_acc,\n",
    "    \"SVM\": svm_acc,\n",
    "    \"k-NN\": knn_acc\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy']).sort_values(by='Accuracy', ascending=False)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c0dd9-91ae-4811-928c-b164d8346e89",
   "metadata": {},
   "source": [
    "## Best Performing Model: Most likely Random Forest or SVM, depending on dataset split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3138034-4045-44de-a54c-4a33892bfac0",
   "metadata": {},
   "source": [
    "## Worst Performing Model: Typically, Decision Tree or k-NN, due to overfitting or sensitivity to data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a86d2-25e5-415e-96d5-8f2e1c2a7bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
